# Preferences under uncertainty (and over time) {#uncertainty}


'Expected Utility';  risk-aversion, finance and diversification; time-preference and discounting



```{block2,  type='note'}

*More content likely to be added.*

This material is largely drawn from O-R Chapter 3, but I also consult a number of other sources as well as  my own notes. You are advised to read most of this O-R chapter along with this web-book. But please see my [notes below](#unc-readings) on what you can skip.
```

<div class="marginnote">

Here we follow the order of O-R in covering preferences under uncertainty *before* consumer behavior and demand. Either ordering is possible, but the idea is to fully cover the 'primitives' of the model before considering it's implications.

</div>

## Introduction


Previous discussion:  Choices with *known* consequences


`r format_with_col("But in the real world many important economic decisions involve uncertainty.","gray")`

<br> <br> \bigskip

Here: Choices with *unknown* consequences (but known *probabilities* of each outcome)

<div class="marginnote">
Adv: In the real world, people may also make choices in contexts with unknown probabilities; this is called 'ambiguity' or 'Knightian uncertainty'. This is out of the scope of this module. (But this is the sort of extension that may motivate a good project).
</div>

How can we consider this in a choice (or utility-maximisation) framework?

The standard framework for this involves maximising 'expected utility'.


```{block2,  type='warning'}
Making choices to maximise expected utility is *not* the same as making choices to maximise expected monetary outcomes. This is one of the main points here.

Do not get this mixed up! You must understand this distinction to consider yourself an 'intermediate microeconomist' or better.

```


```{block2,  type='note'}

**Some summary notes**

Previously described utility functions: predict choices under certainty. They made no predictions for choices with uncertain probabilistic outcomes!

People don't "maximise expected monetary value": they tend to be risk-averse

An *Expected Utility* (EU) framework, as defined below, allows for risk-aversion or any other attitude towards risky *outcomes*

```

### Main Readings {-#unc-readings}

*Web book*, and also...

- O-R Chapter 3: "Preferences under Uncertainty"


*Feel free to skip the following* (unfold)

```{block2,  type='fold'}

Feel free to SKIP:

... the proof of propositions 3.2 ('Continuity and independence implies EU'). It's interesting but we can't cover everything.

If you don't understand the proof of prop. 3.3. (the equivalence of risk aversion and the concavity of the Bernoulli function) that's also OK.

```

- McDL: 13.3 on 'dynamic choice'

\

**Other resources/references** (unfold)


```{block2,  type='fold'}

- QMC: Ch 5, optimization and risk; selections (good discussion of diversification but doesn't use utility functions)

- DA: [Lecture Note 16: Uncertainty, Risk Preference, and Expected Utility Theory](https://ocw.mit.edu/courses/economics/14-03-microeconomic-theory-and-public-policy-fall-2016/lecture-notes/MIT14_03F16_lec16.pdf)

- NS: Ch 4 (not including 4a)

- McDL: Ch 13, section 4 'Risk Aversion'


\

Supplementary recommended readings:

- Holt, C., and S. Laury (2002), Risk Aversion and Incentive Effects, American Economic Review, v. 92 (5): 1644-1655.

- To add: other work on measuring risk aversion and the reliability of distinct measures

- For a popular audience: Reinstein (2016) 'Should you hedge your bets on a Brexit?' [LINK](https://davidreinstein.wordpress.com/2016/06/19/should-you-hedge-your-bets-on-a-brexit/)

```

\

## Probability concepts and notation (including sums and integrals): a quick review

```{block2,  type='note'}
You must understand the logic and notation of probability to understand this (and much more material in your degree). If you already know this stuff, feel free to skip/skim.

```

Probability (informal definition)
:     The relative frequency with which an event occurs, or can be expected to occur.

- Always between 0 and 1


<div class="marginnote">

Note, there are some debates, e.g., between 'Bayesians' and 'Frequentists' over the meaning of probability.

</div>

<div class="inputq">
Q: If $p$ is the probability an event occurs, what is the probability this event does *not* occur?
</div>

```{block2,  type='fold'}
Ans: $1-p$

If you didn't find this obvious, I would suggest seriously revising simple probability, perhaps using the Khan academy materials.

```

\

<div class="marginnote">
Some of the discussion of these  probability basics comes from Anne Greenbaum Wash U notes)
</div>

### Discrete Random Variables

```{block2,  type='note'}

The O-R chapter on uncertainty considers only discrete 'lotteries' ... those with a finite number of prizes. However, outcomes described by continuous random variables will likely come up in other material, and these are extremely important for Finance, as well as for Econometrics and many other fields.

```

A discrete random variable $X$ takes on values $x_i$ with probability $p_i$,
$i=1, \ldots, m$, where $\sum_{i=1}^{m} p_i = 1$.


<div class="marginnote">
For example, the outcome of a lottery ticket that pays a prize of £100 with probability $\frac{1}{2}$, a prize of £10 with probability $\frac{1}{10}$, and nothing (£0) with the remaining $\frac{4}{10}$ ... can be naturally expressed as a discrete random variable.
</div>


<br> <br> \bigskip

The *expected value* (EV) of a discrete random variable $X$ is defined as

$$E(X) \equiv \langle X \rangle = \sum_{i=1}^m p_i x_i$$

...also called the *mean* of the random variable $X$, denoted as $\mu$.

\

`r format_with_col("Also see the 'variance' and other 'moments'.","gray")`

<br> <br> \bigskip


### Continuous Random Variables

A 'continuous random variable' takes on any of an infinite number of values within a range.

An example: the possible exact duration of rainfall (in hours, seconds, milliseconds....) to fall on Exeter in Summer 2025 is most naturally expressed as a continuous random variable.

<div class="marginnote">

If you are not familiar with this concept, you should try to understand it, at least for your studies in general; consult Khan academy and other tutorials. This is a very important concept but takes some time to fully comprehend.

</div>


If it has no 'mass points'then we can only express the probability of it falling *within* an interval.

"Mass points" explained (unfold)

```{block2,  type='fold'}
A "mass point" would describe a specific exact value of a continuous variable that occurs with a positive probability.

With rainfall and with most naturally occuring phenomena it is hard to imagine that this is possible.

But for 'measured rainfall' we might expect that there is a positive probability of 'zero measured rainfall'.

Perhaps in the context of income it's reasonable to expect substantial 'mass points' at round numbers … e.g., many people may earn exactly £50,000 per year.


```


\

*Cumulative distribution function*:

$$ F(x) \equiv \mbox{Prob}(X < x ),$$

This is essentially a function that specifies "the probability of random variable $X$ falling (at or) below some level x."

E.g., $F_r(103.4) =  \mbox{Prob}(X < 103.4 )$...

"the probability of 103.4 hours or fewer of rainfall ($X$) in Exeter for Summer 2025".


\


The *probability density function* (pdf).

$$ f (x)\,dx \equiv \mbox{Prob}( X \in [ x, x+\,dx ] ) = F(x+\,dx ) - F(x) .$$

\

This function is not really interpretable on its own. You might be tempted to read it as 'the probability of exactly a certain value, such as 'exactly 103.4 hours of rainfall', but this would be incorrect (unless we have mass points).  It is best thought of as the 'rate of change' of the CDF, as the limit of the difference in the CDF function for each small interval.

Letting $dx \rightarrow 0$:

$$ f (x) = F' (x) ,~~~F(x) = \int_{- \infty}^{x} f (t)\,dt .$$

\
The 'standard normal density function' is depicted below:
```{r}

curve(dnorm(x),
      xlim = c(-3.5, 3.5),
      ylab = "Density", 
      main = "Standard Normal Density Function") 

```

If a variable has this (or any) probability distribution, we can determine the probability that it falls in any particular region by computing the *area under the curve* between these regions, i.e., computing the integral between these regions. 

<div class="marginnote">
For some distributions, like the normal distribution or the uniform distribution, we can compute all of these 'analytically', i.e., we have a formula.  In other cases we will need to 'simulate' these through a process of drawing random numbers.
</div>
 
\

Below [(link here)](https://bookdown.org/machar1991/ITER/2-pt.html), a very useful review of probability theory that also shows you how to compute and plot these using the `R` language.

<div class="marginnote">
You don't need to learn how to compute these in `R` for this module, but it may aid your understanding, and may be helpful for your future work. 

This material is from the web version of 'Introduction to Econometrics with R', 
Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer
</div>
   
```{r}
knitr::include_url("https://bookdown.org/machar1991/ITER/2-1-random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables")
```



The expected value  (EV) of a continuous random variable $X$ is then defined by
$$ E(X) = \int_{- \infty}^{\infty} x f (x)\,dx .$$


<br> <br> \bigskip

Note that by definition, $\int_{- \infty}^{\infty} f (x)\,dx = 1$.


\

Expected value
:     The 'average outcome' of an uncertain variable (general definition)

<br> <br> \bigskip

:     The average monetary (or goods) payoff from an uncertain gamble

<br> <br> \bigskip

:     The sum of the value at each possible outcome, weighted by the probability that outcome will occur

```{block2,  type='technote'}

When outcomes are in a continuous space, e.g., the returns to a stock can take any of an infinite number of possible values, the expected value becomes a definite integral rather than a sum.

```

This is *NOT* the same as expected utility (coming up); people don't necessary choose the investment with the highest expected value!

## "Lotteries"

O-R, p. 31:

> An alternative in the set involves randomness regarding the consequence it yields. We refer to these alternatives as lotteries. For example, a raffle ticket that yields a car with probability 0.001 and nothing otherwise is a lottery. A vacation on which you will experience grey weather with probability 0.3 and sunshine with probability 0.7 can be thought of as a lottery as well.


\

### Formal definition of Lotteries (from O-R), explanation


<div class="marginnote">
DR Todo: I intend to add a video here discussing this
</div>

<div class="marginnote">
In other texts you may see these  referred to as "simple gambles".
</div>



> Let $Z$ be a set (of prizes).

$Z$ could be a list of amounts, say $\{0,10,100\}$ or a list of bundles of goods, say {(nothing),(apple and carrot), (two carrots)}.


> A lottery over $Z$ is a function $p : Z \rightarrow \mathbb{R}$...
> that assigns a positive number (probability) $p(z)$ to a finite number of members of $Z$ and $0$ to all other members,

Simplifying this, the probability function $p$ 'tells you the probability of each outcome ($z$) among the set of possible outcomes ($Z$)' for this lottery.  

> with $\sum_{z \in Z} p(z) = 1$.

(Unfold for further explanation of this)
```{block2,  type='fold'}

The sum of the probabilities of each possible outcome must be 1... 'one of the possibilities must happen'.  (Note that this also implies that no individual probability can exceed 1, so $0 \leq p(z) 1$ for all 'possibilities' $z$.)

```

\

> We denote the set of all lotteries over $Z$ by $L(Z)$

(Unfold)
```{block2,  type='fold'}

For the example I give above, this means $L(Z)$ is 'any possible lottery with some  some probability of "apple and carrot", some probability of "two carrots", and (the remaining) probability of "nothing". Each of these probabilities could be anything between 0 and 1.

```

>  the lottery that yields the prize $z$ with probability 1 by [z]

<div class="marginnote">
$[z]$ represents a trivial case (sometimes called a 'degenerate' lottery). A 'certainty' is also a lottery, by this definition.
</div>


> and the lottery that yields the prize $z_k$ with probability $\alpha_k$ for $k = 1,..., K$

<div class="marginnote">
I.e., each prize $z_k$ occurs with probability  $\alpha_k$ ... so  $z_1$ occurs with probability  $\alpha_1$, etc.
</div>

> by $\alpha_1 \cdot z_1 \oplus \alpha_2\cdot z_2 \oplus ··· \oplus \alpha_K \cdot z_K$

\

This is a very handy notation but it needs some explanation (unfold).

```{block2,  type='fold'}

We are trying to concisely depict a lottery with K possible outcomes (where K can be any number). Each of these possibile outcomes is indicated by $z_1$, $z_2$, ... etc., all the way up to $z_K$.

Each of these possibities has some probability of occuring. We denote these possibilities by $\alpha_1$ for outcome $z_1$, $\alpha_2$ for outcome $z_2$, etc.

E.g., for a two-outcome lottery, rather than writing 'a lottery where outcome $z_1$ occurs with probability $\alpha_1$, $z_2$ occurs with probability $\alpha_2$, etc., we can simply write it as $\alpha_1 \cdot z_1 \oplus \alpha_2\cdot z_2$. Here the $\oplus$ means 'and also outcome...' and the $\cdot$ means 'with probability'.

```


<div class="marginnote">
TODO: I might include a video here explaining this notation and giving examples
</div>
\

```{block2,  type='inputq'}
How would you use this notation to depict "a lottery with a 1/3 probability of an outcome with value 10, and a 2/3 probability of an outcome with value 100"?
```

```{block2,  type='fold'}

$10 \cdot \frac{1}{3} \oplus 100\cdot \frac{2}{3}$

```

\

```{block2,  type='inputq'}

Consider the diagrams in figure 3.1 in O-R. Can you explain what the points depicted mean? Could you depict the lottery $\frac{3}{4} \cdot z_1 \oplus \frac{1}{4}\cdot z_2 \oplus 0\cdot z_3$ in a 3-D diagram similar to figure 3.1b? (by the way, this is called a 'probability simplex').

```

<div class="marginnote">
(Possible video here)
</div>
 

## Preferences over lotteries

We now have the tools consider the question that motivated this: how might an individual choose among a set of uncertain choices, and what can we say about this?

Formally, what are the "preferences over the set of lotteries $L(Z)$” and “what restrictions over these preferences seem reasonable”?


```{block2,  type='note'}

Please learn the precise definitions of these concepts from the O-R text, whether or not I spell them out here.
```  

<div class="marginnote">
DR Todo: I intend to add a video here discussing this... I want to convey why the 'Expected Utility framework' is not obvious.
</div>

\

O-R consider some 'examples' of preferences (or categories of preferences) over these lotteries that may seem rather extreme;

<div class="marginnote">

We might instead consider these as "simple decision rules" or "heuristics" rather than actual preferences. Behavioral economics considers that people may adopt such simplifying rules instead of maximizing perfectly in the complete set of alternatives, particularly because such maximization is mentally costly.

Of course it is doubtful that anyone completely has these preferences or follows these rules all the time. Still, it is instructive to consider what doing so would mean. It's worth reading these definitions carefully, and then we can consider how these diverge from the "expected utility" framework we will discuss in a moment.

</div>

- **Ex. 3.1 "A pessimist"**: Essentially, someone whose preferences among these lotteries simply depends on "which one has the worst possible outcome ($w(p)$) that is least bad". (Where 'worst' is according to some particular ranking... which can have any form.)

- **Ex 3.2 "good and bad"**: This person divides all possible outcomes into "good outcomes" and "bad outcomes" (in some particular way...there are many possibilities for doing this.)  They simply prefer the lottery which has the highest probability of a "good" outcome (or conversely the lowest probability of a bad outcome).

<div class="marginnote">
TODO: I intend to include a video here discussing the 'good and bad' preference. 
</div>



- **Ex 3.3 minimizing options**:  This person doesn't actually care about the content of any of the outcomes; they simpler prefer the lottery with the fewest possible outcomes.


<div class="marginnote">
This seems to me to be a sort of 'opposite extreme' to the pessimistic preference.  While the pessimist is extremely sensitive to the very worst thing, the "good and bad" person is insensitive to whether the "good things" are 'really good or just OK'  or whether  the bad things" are really bad or just a bit mediocre.
</div>

## Properties of preferences (O-R 3.2.1)


```{block2,  type='note'}

**Some notation: **

Lotteries $L(Z)$ involve possible outcomes drawn from the 'prize space' $Z$. E.g., a lottery could be a 0.25 chance of each of outcomes 0, 10, 100, and 1000, drawn from the 'prize space' $\mathbb{R}^{+}$, the space of positive real numbers.



$E(p)$ denotes (basically) the expected monetary value of the lottery.


O-R use brackets to denote a 'certain outcome', 

e.g., $[b]$ represents 'outcome $b$ occuring with probablity one.'

```  



<div class="marginnote">
TODO: I intend to include a video here going over the formal notation and understanding of  each of these properties.
</div>

\

**Continuity of VnM preferences** 

"Some probablistic mix of a great thing and a terrible thing will be as good as an OK thing"


```{block2,  type='note'}
Note that this is distinct from the continuity of preferences over certainties [defined in the previous section](#continuity) 
```  

```{block2,  type='def'}

More formally (from O-R): 
  
> For any set $Z$ of prizes, a preference relation $\succsim$ over $L(Z)$ is continuous if for
any three prizes a, b, and c in $Z$ such that $[a] \succ [b] \succ [c]$ there is a number
$\alpha$ with $0 < \alpha < 1$ such that $[b] \sim  \alpha \cdot a \oplus (1 − \alpha) \cdot c$. 

```  


\

```{r  fig.cap = '', out.height='20%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","continuity_scribble.png"))
```




- Counterexample: Pessimistic preferences are *not continuous* (counterexamples help illustrate the 'bite' of a property)

<div class="marginnote">
Note that this definition of continuity is remeniscent but not identical to the definition of continuity for preferences over certain outcomes, which you may have seen before, and which we will return to in the next chapter. One difference is that here we are not considering making a bundle that is itself similar to bundle $b$, but we are considering a probablistic conbination of two other bundles, a and b.
</div>
 



\

**Def: Compound lotteries**

- Important;  might be considered an 'algebra of finance'...
- a distributed format
- 'sum product of x across all lotteries $p_1...p_k$'

\

**Def: Independence**

"If I prefer a particular (certain) A over a particular lottery B, I also prefer to increase the probability of A over B... in a 'compound lottery'"

- Counterexamples: pessimistic preferences, 'minimizing options'
- Note how, in this case, a property over $\succsim$ extends to $\succ$

<div class="marginnote">
Independence and pessimistic preferences are relevant to 'population ethics' and 'effective altruism' and 'other-regarding preferences', and 'social welfare functions/social preferences'. E.g., sometimes we must decide between 'making a big positive difference with a high probability' (e.g., providing bednets to prevent malaria) and 'making an extremely large positive difference with a very small probabillity' (e.g., building a system to block an asteroid from destroying the earth).
</div>

\

**Def: Monotonicity of VnM preferences**

"A lottery (between two things) gets better as the better thing gets more likely"

- Independence implies monotonicity; a fairly easy and cool proof.


## Expected utility

Expected Utility is the 'most commonly assumed' framework in economic theory. We will consider certain “axioms” that seem reasonable, particularly the ‘independence’ axiom. We can formally prove that "if people’s preferences obey these axioms, then their preferences must be 'consistent with expected utility'".

<div class="marginnote">
Again, this method...
- Define axioms that seem reasonable
- prove what this implies (in terms of 'maximizing behavior')
...
is sometimes called "normative Economics".  But this is confusing as "normative" is also used to refer to several other things. I hate that word!

</div>

However, Expected Utility preferences (choices) rules out some stated preferences (and choices) that seem common. We will see this in the [“Allais Paradox”](#allais), for example.


\

**Under this framework**

When evaluating alternatives (or, if optimising, when making choices) involving uncertainty, she does **not** (necessarily) maximise expected monetary value.

Instead, she maximises 'Expected Utility' (EU): the sum of her (VNM) valuations '$v(\cdot)$' under each outcome weighted by the *probability* of each outcome. (O-R refer to this as the *Bernoulli function*.) 

<div class="marginnote">

I use the $v(\cdot)$ function notation rather than $u(\cdot)$ to differentiate the utility over a lottery in the EU framework ($U$) from the utility of one possible outcome of that lottery ($v$). However, in the EU framework we see that that the EU of a 'degenerate lottery' containing  outcome $z$ with probability 1 is simply $U(p) = p_z \times v(z) = 1 \times v(z)$.

</div>
 


... I.e., she chooses to maximise the value of her $v(z)$ function under each outcome $z$ weighted by the probability of each outcome $p_z$.

<div class="marginnote">
While I describe a set of countable alternatives, O-R define the below over the more general idea of a 'set of lotteries $L(Z)$ over prizes $Z$'.


</div>

\


<div class="marginnote">
TODO: I intend to include a video here 
</div>

```{block2,  type='def'}

**Definitions:**
  
Remember, each lottery $p$ is a set of probabilities over each possible alternative. With a finite set of $n$ alternatives $z_1, z_2, ...,z_n$ we have probabilities $p_1, p_2, ..., p_n$ over each.

Consider the "Expected Utility" function $U$. This has a particular form. It is defined over each lottery $p$ as:

$$U(p)= \sum_{i=1}^{n}p_i v(z_i)$$.

Where $v(\cdot)$ is a 'value function' (aka 'sub-utility function', aka 'Bernoulli function').

\

If an individual's preferences (choices) are 'consistent with this',

- so she always prefers (chooses) the lottery with the highest value of the above sum,

- for some specific $v$ function (which is the same $v$ function across lotteries, of course),

... then we say she has 'Expected utility' ('EU', or von-Neumann Morganstern) preferences (if she *chooses* according to these preferences, she is an 'EU maximizer').

```

\

Note that the above does not specify *what* the $v$ function must be. Obviously this may differ across individuals.

\

When we dealt with certainties, utility was 'ordinal'. All we could say or know is whether “A yielded more utility than B or vice versa”.

However, if we assume EU preferences and focus on the $v$ function, now the *magnitude* of the difference matters. Furthermore, it is now meaningful to consider the "curvature" of this $v$ function in a single good which we could just call ‘wealth’.


\

*Unfold for a further discussion of this; which may make more sense after reading further*

```{block2,  type='fold'}

With uncertainty, linear (affine) transformations of the $v$ function represent the same preferences and thus lead to the same behaviour; nonlinear monotonic transformations may not.

\

Formally, if the VNM utility function $v(\cdot)$ represents a set of preferences, the VNM utility function $w(\cdot)$ represents the same preferences if and only if, for some scalar $\alpha$ and some scalar $\beta>0$

$$w(g) = \alpha + \beta v(g).$$

\
Note that when we were choosing between two goods under certainty,
the *level* of total utility didn't really matter, only the relative utilities. Now that we are considering gambles, the overall utility level matters, because we need to consider the extent of the tradeoff between 'rich and poor' states.

```

\

By varying the $v(\cdot)$ function we can vary what we will define as  the '[risk preference](#risk-pref)'; ...Risk-loving, risk neutral, and risk averse individuals can all be seen as maximizing EU, as discussed [below](#eu-risk).


```{block2,  type='tip'}

Although O-R cover the Allais paradox next, I think it may be easier to understand after considering EU and risk preferences. Thus I consider it [further down](#allais) and again when we consider behavioral economics, time permitting. 
```  

\

## Risk preferences {#risk-pref}

 
Consider the choice between two gambles and one 'certainty':

1. Earn £1,000,000 with probability 0.1 \& zero with prob. 0.9
2. Earn £100,000 with probability 1/2 \& £50,000 with prob. 1/2
3. Earn £75,000 for certain

<br>  \bigskip

```{block2,  type='inputq'}

Consider: which do you think you would choose? What would you predict others will choose, and why? Are any of these 'clearly better' than any other?
```

\

The decision among such lotteries depends on an individual's preferences, in particular, her 'risk preferences'. We divide up the space of possible preferences with the following definitions...

\


**Definitions (loose):**

1. Risk Neutrality: a *Risk-neutral* person always chooses the option with the highest *expected monetary value*

<div class="marginnote">
Expected monetary value: the probability-weighted sum of the monetary outcomes. E.g., above, choice 2 as an expected monetary value of £100,000 $\times \frac{1}{2}$ +  £50,000  $\times \frac{1}{2} = $ £75,000.
</div>

```{block2,  type='inputq'}

Consider: what sort of $v$ function, a function of monetary income, would have the property that

.... it implies that the expected utility (the probability-weighted sum of the $v$ terms) of a  gamble is always higher when the expected monetary value of this gamble is higher?

```

```{block2,  type='fold'}

Answer: Such a $v$ function must be linear (or affine);

it must take the form $v(y)= a + by$ for some $b>0$.

Can you prove this?
```


\


<br>

2. Risk-Averse: a *risk-averse* person will always prefer a 'sure thing' over a 'gamble with the same expected monetary value'

- She will always prefer gambles with less risk, holding the expected value constant
- She will always reject 'fair gambles' (see below) and prefer certainties
- To accept a (fair) gamble, she must expect a 'risk-premium'

\
<!---
```{r  fig.cap = '', out.width='70%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","weirdalscissors.jpg"))
```
-->


3. A *Risk-lover* will always choose fair gambles over certainties, and sometimes choose a gamble that is unfair against her.

\

```{block2,  type='def'}

**Formal definitions of risk preferences from O-R** (emphasis added):
  
Recall that lotteries $L(Z)$ involve possible outcomes drawn from the 'prize space' of positive real numbers. E.g., a lottery could be a 0.25 chance of each of outcomes 0, 10, 100, and 1000.
  
> If $Z = \mathbb{R}^{+}$ 
> a preference relation  on the set $L(Z)$ of lotteries over $Z$ 
> is **risk-averse** if $[E(p)] \succsim p$ for every lottery $p \in L(Z)$

Recall  '$[E(p)]$' denotes (basically) the expected monetary value of the lottery occuring with probability 1, a weighted sum or integral, formally $E(p) = \sum_{z \in Z} p(z)z$ 
<div class="marginnote">
Of course it doesn't have to be 'monetary value' ... it could equivalently be a measure of the size of a bundle of goods.
</div>
 

So this defines *risk averse* as 'weakly preferring a certainty to a lottery with the same expected monetary value'  

  
>  is **strictly risk-averse** if $[E(p)] \succ p$ for every lottery $p \i L(Z)$ that involves more than one prize, 

> and is **risk-neutral** if $[E(p)] \sim p$ for every lottery $p \in L(Z)$, 
  
```

### Risk preferences and EU {-#eu-risk}

Imagine the realised utility $v(y)$ that arises from the consumption chosen with wealth $y$. H$.
ere we will express this as the (similar concept) 'indirect utility function' $V(y)

<div class="marginnote">

This is referred to as a 'indirect utility function', and sometimes written in capitals as $V(y)$: an indirect utility function maps the utility that can be attained (assuming optimal choices) as we shift an individual's wealth (and prices).

TODO: link notes on this

</div>

- This should be increasing (because of nonsatiation, 'more preferred to less'), thus (assuming differentiability) $V^\prime (y)>0$

- But it may increase at a *decreasing* rate, implying $V^{\prime \prime}(y)< 0$

This second assumption, called *diminishing marginal utility*,  will imply 'risk aversion'! (This is a 'sufficient condition').

If the person is 'risk-neutral', it must be linear, thus $V(y) = a + by$, thus $V^{\prime \prime}(y)=0$

<br>

```{block2,  type='note'}

Add: formal statement and proof that risk aversion depends on the concavity of Bernoulli (value) function $v(\cdot)$, (Prop 3.3 in O-R)
```  



<br> 

### Further intuition and discussion {-}

Coming back to the choice between two gambles and one 'certainty':

1. $Y_1$: £1,000,000 with probability 0.1 and zero with prob. 0.9
2. $Y_2$: £100,000 with probability 0.5 and £50,000 with prob. 0.5
3. $Y_3$: £75,000 for certain

\



Considering each *outcome* from any of these...

we know $u(1,000,000) > u(100,000) > u(75,000)> u(50,000) > u(0)$...

but now the *size of the difference* in these utilities matters for your decision!


<br> 

- Consider Y1 vs Y3: Is 1 million 'more than ten times as good (utility-wise) as 75k?'

- Y2 v Y3: Relative to 75k, does an additional 25k yield a utility gain worth the (equally probable) loss of 25k?

\


**Illustration:** Why the 'size of the difference in u(y) matters' when dealing with uncertainty.

Suppose there is Open Enrollment in Oxford, Bristol, Plymouth.

$\rightarrow$ Here I only need to know the *ranking* of utilities of each to know your choices.

- If you choose Oxford over Bristol, even though Oxford costs more, I can infer that for you $u(Oxford)>u(Bristol)$

<br> 

Now, in contrast suppose there is a "Lottery policy", which is:

> A. Rank Oxford over Bristol and you have a 25\% chance of getting into either, and a 50\% chance of Plymouth.

> B. Rank Bristol highest and you have a 100\% chance of getting into Bristol.

\


```{block2,  type='inputq'}

Now, suppose that I know that your preferences are  Oxford $\succ$ Bristol $\succ$ Plymouth.

Do I now know whether you will choose A or B? What would it depend on?

```  

\

```{block2,  type='fold'}

No. I don't know if you will choose A or B; I would need to know the *strength* of your preferences.

```


<br> 

```{block2,  type='inputq'}

So, which tells me more about your preferences: your choices under Open Enrollment or your choices under the Lottery policy?
  
```  

```{block2,  type='fold'}

Your choices under the Lottery policy can be more informative. 

\

If I observe that you choose 'option A' under the Lottery policy I have learned *more* about your utility than I learned under Open Enrollment.

I have learned that your preference for Oxford over Bristol is  "stronger" than your preference for Bristol over Plymouth.

```


### Intuition for 'risk aversion iff concave value function $v(\cdot)$' {-}

Risk aversion is defined (at least one definition) as being unwilling to take any "fair gambles" (gambles with an expected monetary value of zero) not even small ones.  A risk averse person would never be willing to take on an equal probability of gaining a certain amount and losing that same amount.  If they are "globally risk-averse" this holds no matter what level of income/wealth they start at, and no matter how large or small this amount is.

\

If the value function is strictly concave that means it is 'everywhere increasing at a decreasing rate'.  This means that, starting from a single point the rate of increase above this point is always lower than the rate of decrease below this point.  A small loss is always at least somewhat more costly than a small gain of an equal monetary value. 

\

Thus a risk-averse person would reject such gambles.

\

### Graphical illustration of "risk aversion $\leftrightarrow$ the value function $v(\cdot)$ is concave" {-}

**How to illustrate this:**

<div class="marginnote">
TODO: I intend to include a video here 
</div>

- Show: $EU(gamble) = (1-p)u(x_{low}) + pu(x_{high}) < u(EV(x)) = u((1-p)x_{low} + px_{high})$

Draw a diagonal line between $u(x_{low})$ and $u(x_{high})$; the Expected Utility is in between these.

To find this expected utility: 

1. Go horizontal distance $p$ of the way between $x_{low}$ and $x_{high}$
2. Project up to the diagonal for the 'average of functions (EU)'

<div class="marginnote">

This is a mathematical/graphical property we can easily prove.

Intuition: The slope of a line tells me 'rise for a given run', the 'expectation' calculation is a linear function, so the slope is constant
and the 'share of the rise' simply projects up from the 'share of the run'
</div>
 


- Compare this to the vertical height of utililty function at same point $(1-p)x_{low} + px_{high}$

\


The result that the EV of the gamble is less than the EV of the certainty is actually a special case of *Jensen's inequality* (unfold if you are interested )

```{block2,  type='fold'}

For a strictly concave function $f(\cdot)$ and for constant $t \in [0,1]$

$$f(tx_1+(1-t)x_2) > tf(x_1)+(1-t)f(x_2)$$ ...

extended to expected values for a random variable $X$ ...

$$f(E(X)) > E(f(X))$$

```



```{r  fig.cap = '', out.height='35%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","riskaversion1.png"))
```

*Note: You start with \$35k*

```{r  fig.cap = '', out.height='35%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","riskaversion2.png"))
```


```{r  fig.cap = '', out.height='35%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","riskaversion3.png"))
```


```{r  fig.cap = '', out.height='85%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","riskaversion4.png"))
```


```{r  fig.cap = '', out.height='85%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","riskaversion5a.png"))
```

\



## Allais paradox; considering other (non-EU) frameworks {#allais}

<!-- #TODO (Content to be added here, drawing both from O-R and from my previous notes) -->


### Simple depiction of Allais paradox {-}

Consider: 

**Scenario 2. Which would you choose?**

- Gamble A: an 89\% chance of winning £1 million, a 10\% chance of winning £5 million, and a 1\% chance of winning nothing.
- Gamble B: £1 million with certainty.

\

```{block2,  type='inputq'}

Write down (in Hypothesis): which would you choose?

```  

<!--#TODO: add a survey link -->


\hrulefill

\

**Scenario 2. Which would you choose?**

- Gamble C: an 89\% chance of winning nothing and an 11\% chance of winning £ 1 million.
- Gamble D: a 90\% chance of winning nothing and a 10\% chance of winning £5 million.

\


```{block2,  type='inputq'}

Write down (in Hypothesis): which would you choose?

```  

\

Many people choose B over A and choose D over C. But look what this implies!!:

$$B \succ A $$

$$ £ 1m \cdot 1\succ  £ 1m \cdot 0.89 \oplus £ 5m \cdot 0.1 \oplus £0 \cdot 0.01$$

\

At the same time...

$$D \succ C $$

$$(£ 0 \cdot 0.9 \oplus  £ 5m \cdot 0.10) \succ (£ 0 \cdot 0.89 \oplus £ 1m \cdot 0.11) $$

i.e.,

$$ £ 1m \succ  (£ 1m \cdot 0.89 \oplus £ 5m \cdot 0.1 \oplus £0 \cdot 0.01)$$
\



*But this contradicts Expected Utility maximization:*

If $B \succ A$ then $EU(A) > EU(B)$

- $\rightarrow u(1m) > 0.89 \: u(1m) + 0.1 \: u(5m) + 0.01 \: u(0)$
- $\rightarrow$ $0.11 \: u(1m) >  0.1 u(5m) + 0.01 \: u(0)$

\

Yet if $D \succ C$ then $EU(D)>EU(C)$

- $\rightarrow 0.9 \: u(0) + 0.1 u(5m) > 0.89 \: u(0) + 0.11 \: u(1m)$
- Implying $0.1 \: u(5m) + 0.01 \: u(0) > 0.11 \: u(1m)$
- Contradicting the above!

\


*More intuitively, note there is a 'reversal':*

In choosing B over A you gave up a 10\% chance of £5000 to get a 1\% greater chance of £1000 \
... but in choosing D over C you gave up a 1\% greater chance of £1000 to get a 10\% change of £5000



For EU mazimization it shouldn't matter that 'for the remaining 89\% of the time A differs from C'.... (unfold)

```{block2,  type='fold'}

This is an 'independent state of the world'; it should have no impact on your decisions for the remaining 11\% of the time.  Remember the 'independence property'?

By this logic, the fact that there is a 10\% chance that a meteor destroys England on Friday should not affect my choice \

of whether to go to a fancy restaurant or get a simple curry on Friday in the 90\% probability case that England is *not* hit.

```

\

**Explaining it again with pie charts...**

```{r  fig.cap = '', out.width='85%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs", "allaispies.png"))
```

\

A is D plus an additional  89\% chance of £1m


B is C plus an additional 89\% chance of £1m


So "A and B" are "D and C" with **additional 89\% chance of £ 1m**


\

EU is *additive*: $\rightarrow$: \footnotesize{choice for *remaining* 11\% state ignores **difference**

By the EU calculation I make choices over which I prefer for the (remaining)
 11% of the time without considering what happens 89% of the time. 'Independent states of the world'.

\



**SO WHY do people choose B over A and D over C?**

One theory: People may maximize something like EU but they get the probabilities wrong.  They overweight small probabilities.

- $\rightarrow$  Gamble A: the 1\% chance of 0 is treated as larger?

\

```{block2,  type='note'}
Another theory: 
People do *not* choose in a way that could be characterised as maximizing the probability-weighted sum of a value function over outcomes. They do not do anything that could be depicted as EU maximization. Instead, the assess gambles using other criteria, perhaps framing 'reference points', and 'gains and losses' relative to this reference point. We will (time permitting) return to this in our discussion of 'prospect theory' when we consider Behavioral Economics. 
```  



\

## Experimental measures of risk attitudes

Economists try to measure people's level of risk aversion in various ways.

We try to measure 'revealed preferences' from real-world choices. E.g., what premium are people willing to pay to buy insurance for various things,  how much premium do they demand for taking on risky investments (with the same expected monetary values), and how much more do they have to be paid (on average) in jobs with variable compensation?

<br> <br> \bigskip

We also run *experiments* with real or hypothetical payoffs to measure this.


<div class="marginnote">

Although it is widely used, the validity of the Holt and Laury method is disputed, and there are alternatives. (Add/link discussion here)

</div>


One technique is the Holt and Laury (2002) risk elicitation task:

```{r  fig.cap = '', out.width='70%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","holtlaurie.png"))
```

`r format_with_col("Asked to choose one in each row (A or B)","gray")`

- Consider, when would you choose A and when would you choose B?

<br> <br> \bigskip

```{r  fig.cap = '', out.width='90%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","holtlauriedetail.png"))
```

At what point do people switch from choosing the safe to choosing the risky lottery?

This is a measure of their risk-aversion.  A risk-neutral person would switch to B on the fifth choice.
The later you switch, the more risk averse you reveal yourself to be.

\

```{r  fig.cap = '', out.width='50%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs","holtlauryresults.png"))
```

Above: Results for different 'stake sizes'. Most people are risk-averse.  People switch to the risky option later when stakes are higher.

\

```{block2,  type='note'}

**However**, although it has been the most widely used procedure, the Holt and Laury task has been widely criticized, both on theoretical and empirical grounds. There are a variety of proposed  risk elicitation methods, as explored by @crosettoTheoreticalExperimentalAppraisal2016 and @charnessExperimentalMethodsEliciting2013.

It is not clear whether these 'do a good job'. According to [Charness et al, 2020](https://link.springer.com/article/10.1007/s11166-020-09325-6) [@charnessMeasuresRiskAttitude2020].


>...  these measures have some predictive power on behavior in experimental settings, and that the most complex procedure (TCN) is outperformed by simpler procedures. Finally, we find no correlation between field behavior and measures of risk attitude. This finding is confirmed for all of the implemented measures, either simple or complex.

However, the Charness et al 'correlation' results appear largely underpowered.  

Other work finds that simple survey measures do a better job of predicting real world risk-taking behavior [@beauchampPsychometricEmpiricalProperties2017; @lonnqvistMeasuringIndividualRisk2015].


```  


## Applications (esp. to finance):

- How do we express and measure 'risk aversion'?

- How does this affect (financial, investment, insurance) choices?  Why does 'diversification improve outcomes for the risk-averse'?

- How does this affect asset prices (Stocks, bonds, etc.) with 'efficient markets' (this will be briefly defined)

<!-- ### Insurance {-}

(Content to be added)

--> 

### Benefits of diversification {-}

<div class="marginnote">
Content to be added here.
</div>
 
See also QMC, chapters 5-6 for a fairly nontechnical and intuitive explanation

Diversification: Buying multiple assets (with risks that are not perfectly correlated with one another)

- "Putting your eggs in multiple baskets" tends to reduce risk, holding expected monetary value of profit (return) sconstant!

\

### Illustration: Binomial distribution {-}

- Suppose I have £ 1000, and I can bet on fair coin flips. My returns will then have what we call a “binomial distribution”.

\

Consider an illustration of binomial distributions

- If I bet all £ 1000 in a single flip, there is a 50\% chance I will lose my entire investment.
- If I bet £ 500 on two flips, there is only a 25% chance I will lose my entire investment (also reduces chance of doubling by 25\%).
    - The expected value is the same (0); thus this is better if you are risk averse.


<!--#TODO: put in a shiny example here illustrating this -->

"Less risky": B and A overlap with 0.5 probability; the remaining 50\% of time A's outcomes are more extreme. So it is less risky in a very general sense.

- If I bet £ 100 each in ten flips,  there is a 38\% chance that I will lose 20\% or more of my investment.
- If instead, I bet it on 1000 coin flips, betting £ 1 on each, there is only 6.00\% chance I will lose 5% of my investment or more, and only 1/10th of 1\% chance that I will lose 10\% of my investment or more.

\

You can check this, e.g., [here](https://shiny.rit.albany.edu/stat/binomial/)

```{r knitrapp}
knitr::include_app("https://shiny.rit.albany.edu/stat/binomial/",
height = "600px")
```

<br> 

*Result*: The more I can do this “diversification”, the less risk I face.

<br> 


*Note*: For simplicity, these examples have a 'fair coin flip', zero expected-return investment.


\

But you might be wondering: 'why invest at all? 


```{block2,  type='fold'}

Answer: Because this principle also applies to 'unfair coin flips'.


\

E.g., investments in the stock market are more profitable on average than money under the mattress

Each £1 invested in shares has a higher expected return, but also a higher risk.
 However by spreading across *many different* assets we can reduce this risk, as seen above, maintaining the same expected returns. 

\

```


\

### Asset pricing and the CAPM (basic characterization) {-}


```{r  fig.cap = 'Figure reprinted from Nicholson and Snyder, 2010', out.width='85%', fig.asp=.4, fig.align='center',  echo = FALSE}

knitr::include_graphics(file.path("picsfigs", "marketriskline.png"))

```


Market line
:     Shows the relationship between risk and annual returns that an investor can achieve by mixing financial assets.

`r format_with_col("Note typo in diagram: 'risk assets' should be 'risky'","gray")`

`r format_with_col("With efficient markets, line depicts 'best mix': proportional to the total 'market basket', plus borrowing/lending at the 'risk-free rate'","gray")`

\

```{r  fig.cap = 'Figure reprinted from Nicholson and Snyder, 2010', out.width='85%', fig.asp=.4, fig.align='center',  echo = FALSE}
 knitr::include_graphics(file.path("picsfigs", "investorchoices.png"))
```

People may have  different preferences for risk versus *expected* (average) return

(Risk' is the overall variance around the average)

The above assumes 'optimal diversification': no one chooses points *below* market line

\

#### Extension: "Capital asset pricing model" (CAPM) {-}

(*More content/reading to be added here.*)

<!-- #TODO -->

This is the  leading 'baseline' model in finance.

It assumes (or in fact, derives that) investors optimally diversify.

\

Thus assets are priced based only on 'risk that cannot be diversified away from', which is called 'market risk'.

\

Holding the expected value of dividends constant, assets with higher market risk are less desirable, thus priced lower, and get higher returns

The trade-off between this risk and return has a linear relationship, and it has a  slope called  'Beta'.

<div class="marginnote">
Confusing matters further, in some discussions, the measure of the market risk itself is referred to as “Beta”.

You will also hear "Alpha" referred to, representing the intercept and and to depict the excess return of an asset over and above what would be predicted by its market risk.  People who claim to be able to beat the markets will flex about their ‘high Alpha’. But maybe they are just lucky.
</div>
 

\

- Typical boring economist's investment advice: diversify to mimic the 'market basket', choose funds with low fees

This doesn't make you a hit at parties :(

\

```{block2,  type='tip'}

See also QMC, chapters 5-6 for a fairly nontechnical and intuitive explanation.

```  

\

## Options contracts

<div class="marginnote">
The content in this section is largely drawn from Nicholson and Snyder, "Intermediate Microeconomics and Its Application", 2010, Cengage.
</div>
 

Option contract

:     Financial contract offering the right (but not the obligation) to buy or sell an asset over a specified period (at a certain price).


<br> 

Attributes of options:

1. Specification of transaction: what is bought/sold, how many units maximum, at what price, etc
2. Period the option may be exercised (from when until when)
3. Price of the option

\

### Price of options determined by {-}

1. Expected value of underlying transaction (e.g., for a call option, expected future share price minus strike price)

2. Variability of the value of the transaction

Option G (a 'call option'): Right to buy Google share at £500 (£500 'strike price') in December 2020

- Worth more the higher the current share price

- If $P_{google}< £500$ currently, then option G is worth more the higher the expected *variability* in $P_{google}$
    - Variability can only help the option-holder:
    - price increase helps her
    - if price falls below £ 500, she doesn't need to exercise the option

```{block2,  type='warning'}

If you didn't read this you probably would have guessed the opposite. Common sense does not get you everywhere, and definitely not a good mark on exams. I *particularly* want you to understand those results that are *not* common sense.

```  


3. Duration: the longer the better -- a longer duration brings a greater chance that the price will rise above strike price (£500)

Note that the results for 'right to sell = call options' are similar, just replace the words 'buy' with 'sell' and reverse the directions ('rise' with 'fall), etc.


\

```{block2,  type='note'}

Classic economist's argument: you should 'bet against yourself' to minimise risk; but this might give you bad incentives to perform. See column about this [HERE](http://www.marketplace.org/2008/08/11/business/hedging-your-bets-hard-times) ... "Hedging your bets in hard times"]

```
\


\

**Extension: "Capital asset pricing model" (CAPM)**

This is the  leading 'baseline' model in finance.

It assumes (or in fact, derives that) investors optimally diversify.

<br> <br> \bigskip

Thus assets are priced based only on 'risk that cannot be diversified away from' ('market risk')

<br> <br> \bigskip

Holding the expected value of dividends constant, assets with higher market risk are less desirable, thus priced lower, and get higher returns

The trade-off between this risk and return has a linear relationship with slope 'Beta'

<br> <br> \bigskip

- Typical boring economist's investment advice: diversify to mimic the 'market basket', choose funds with low fees

This doesn't make you a hit at parties :(

\

## Measures of risk preferences, further characterizations {risk_measures}

- CARA, CRRA

- Certainty equivalenne

<div class="marginnote">
Content to be added here, drawing from McDL section 13.4.
</div>

\

### Local measures of risk-aversion {-}

- Coefficient of *absolute* risk aversion: $A(m) \equiv -\frac{u''(m)}{u'(m)}$

Note this is preserved under an affine transformation; the value itself may be constant, decreasing, increasing in income...


\


<br> 

- Coefficient of *relative* risk aversion: $R(m) \equiv mA(m)=-\frac{mu''(m)}{u'(m)}$



`r format_with_col("Note that these ideas are also relevant to intertemporal substitution and to social welfare functions","gray")`

RRA (ARA) constant $\rightarrow$ constant fraction of portfolio (number of dollars) held in risky asset as wealth increases.

\

### 'Prudence'  {-}

```{block2,  type='inputq'}

Does 'risk aversion' imply that it will be beneficial to lay aside more savings if you are facing greater risk, i.e., outcomes with greater variance? Why or why not?
  
```  


```{block2,  type='fold'}

Surprisingly, it does not imply this; it can go either way. Why? 
  
Consider the case with two state of the world, "good and bad". Imagine each occur with some probability, perhaps $\frac{1}{2}$.

Consider two people, Sam and Rick, with the same expected value income of 50 'next year'. Suppose both have the exact same risk-averse utility function.  

However, Rick faces a much greater variance of income than Sam. Suppose Rick gets income 10 half the time and 90 half the time, while Sam gets 40 half the time and 60 half the time. 

Now suppose each is considering how much of "this year's" income to lay aside for next year, at the cost of less pleasure this year. (I may not  have covered utility across time and discounting yet, but I think you will get the idea.)

Who will find it more important to put aside money, Sam or Rick? ... think and unfold. 

```

```{block2,  type='fold'}

The answer:  not enough information to say either way.

With  diminishing returns to income (each year)...

- For the 50% 'bad state of the world' (where they have a lower income), the additional savings is more valuable to Rick than to Sam, as increasing from 10 to 11 (say) yields more utility gain than increasing from 40 to 41.
 
- However, for the 50% 'good' state of the world, the additional savings is *less* valuable to Rick than to Sam, as an increase from 90 to 91 is worth *less* utility than an increase from 60 to 61. 

So we don't know without more information about their value functions.

```


\


Economists have a particular definition of something called "Prudence". 

<div class="marginnote">

This is something economists do. We take a normal word and we define it with a particular mathematical meaning that may or may not agree with most people's common sense of that word is.

</div>

We define someone as *prudent* if they are risk-averse *and* if $v'''(y)<0$.  That's right, even the *third derivative* matters, and has an interpretation!

\

Prudence implies that risk is less painful at higher incomes. This implies that I will *save more* when facing greater risk. 

\

That might seem the obvious choice to you, in spite of the above discussion. If so, congratulations on knowing the sign of the third derivative of your value function!


\



## Time preferences and discounting {#time-pref}

(To be added, partly from McDL: 13.3 on ‘dynamic choice’)

# Exercises - uncertainty, finance, time preferences ('problem set')  {-#ex-uncertainty}

Tbd; some possibilities in the fold.

```{block2,  type='fold'}

O-R Q2: "A parent"

O-R Q7: "Additional lottery"

O-R Q8: "Casino"

O-R Q9: "Insurance"

- Proof-based problem

- Example-based problem (lotteries, insurance, investment)

- Allais Paradox question

- Potentially: data/code based simulation

- Discussion/explanation question

```




