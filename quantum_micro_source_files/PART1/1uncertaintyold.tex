\chapter{Optimization and Risk\index{risk}}
\label{1uncertainty}


\subsubsection{Motivating question\rm : What is the maximum amount $\$x$ you would pay to play a game in which you flip a coin and get \$10 if it comes up heads and \$0 otherwise? (See Figure~\ref{fig:dtree_risk}.)}

\begin{figure}[b]
\begin{pspicture}(-4,-3)(16,3)
\pstree[treemode=R]{\TC*}
{
\TC*~[tnpos=r]{\fbox{\parbox{2.5cm}{Gain nothing,

lose nothing}}}
\taput{Refuse bet}
\TC*~[tnpos=r]{\fbox{\parbox{3cm}{50\%: Win $\$10-x$

50\%: Lose $\$x$}}}
\tbput{Take bet}
}
\end{pspicture}
\caption{A decision tree\index{decision tree} involving risk\index{risk}}
\label{fig:dtree_risk} % Figure~\ref{fig:dtree_risk}
\end{figure}

\noindent The important issue in this game is your attitude toward \textbf{risk}\index{risk}. People who are \textbf{risk\index{risk}-averse} buckle their seatbelts and drive safely and buy insurance and otherwise try to avoid risk\index{risk};  if you are this type of person you will be unwilling to pay \$5 or more to play this game. People who are \textbf{risk\index{risk}-loving} go skydiving, drive crazy, or engage in other risk\index{risk}-seeking behaviors; if you are this type of person, you might be willing to pay more than \$5 to play this game (or other types of risk\index{risk} games like the lottery or Las Vegas). People who are \textbf{risk\index{risk}-neutral} are ambivalent about risk\index{risk}; if you are this type of person, you'd be willing to play this game for less than \$5, you'd avoid playing the game for more than \$5, and you would be indifferent about playing the game for exactly \$5.



\subsubsection{What's the Deal with \$5?}

The deal is that \$5 is the \textbf{expected value\index{expected value|(}} of this game. Since you have a 50\% chance of getting \$10 and a 50\% chance of getting \$0, it makes some sense to say that \emph{on average} you'll get \$5. (Section~\ref{diversification} fleshes out this idea.) The concept of expected value provides a valuable perspective by condensing this risky situation into a single number. Note, however, that it conveys only one perspective. In describing the average outcome, expected value fails to capture other aspects, such as the variability of the outcome.\footnote{The concept of \textbf{variance\index{variance}} attempts to convey this part of the story.}

Mathematically, an expected value calculation weighs each possible outcome by its likelihood, giving more weight to more likely outcomes and less weight to less likely outcomes. To calculate expected value, sum probability times value over all possible outcomes:
\[
\mbox{Expected Value}\ \ \  = \ \ \ \sum_{\mbox{Outcomes
\emph{i}}} \mbox{Probability(\emph{i})} \cdot
\mbox{Value(\emph{i})}.
\]
The Greek letter $\displaystyle \sum$ (``sigma'') is the mathematical notation for summation, e.g., $\displaystyle \sum_{y=1,2,3} y^2 = 1^2+2^2+3^2 = 14$. In the game described above, the two possible outcomes are heads (H) and tails (T), so the expected value is
\begin{eqnarray*}
EV & = & \Pr(H) \cdot (\$10) + \Pr(T) \cdot (\$0) \\
& = & \frac{1}{2}\cdot (\$10) + \frac{1}{2} \cdot (\$0) \\
& = & \$5.
\end{eqnarray*}
If it costs $\$x$ to play the game, the overall expected value becomes $\$(5-x)$.


\subsection*{Example: Fair and Unfair Bets}

A \textbf{fair bet\index{fair bet}} is a bet with an expected value of zero. Flipping a coin and having me pay you $\$x$ if it comes up heads and you pay me $\$x$ if it comes up tails is a fair bet\index{fair bet} (provided, of course, that the coin is not weighted). If $x=5$, this is identical to the game above in which you pay me \$5 and then I pay you \$10 if the coin comes up heads and nothing if the coin comes up tails.

An \textbf{unfair bet\index{unfair bet}} is one with an expected value less than zero. If you go to a casino and play roulette, for example, you will see that the roulette wheel has 38 numbers (the numbers 1--36, plus 0 and 00). If you bet \$1 and guess the right number, you get back \$36 (the dollar you bet plus 35 more); if you guess the wrong number, you get back \$0. So if you bet \$1 on, say, number 8, then the expected value of the amount you'll get back is
\[
\Pr(8) \cdot (\$36) + \Pr(\mbox{Not $8$}) \cdot (\$0) = \frac{1}{38}
\cdot (\$36) + \frac{37}{38} \cdot (\$0) \approx \$0.95.
\]
%
Since it costs \$1 to play and your expected return is only \$0.95, the overall expected value of betting \$1 in roulette  is $-\$0.05$. So roulette, like other casino games, is an unfair bet.



\section{Reducing Risk with Diversification}\label{diversification}\index{diversification}\index{risk!reducing with diversification}

Playing roulette once is obviously a high-risk endeavor. (Presumably this is part of what makes it attractive to gamblers.)  It would therefore seem that owning a casino would also be a high-risk endeavor. \emph{But this is not the case.}

To see why, consider flipping a fair coin, one where the probability of getting heads is 50\%. Flip the coin once, and the actual percentage of heads will be either 0\% or 100\%. (In other words, the coin either comes up heads or it comes up tails.) Flip the coin twenty times, though, and the percentage of heads is likely to be pretty close to 50\%. (Specifically, your odds are better than 7 in 10 that the percentage of heads will be between 40\% and 60\%.) Flip the coin one hundred times and the odds are better than 95 in 100 that the percentage of heads will be between 40\% and 60\%. And flip the coin one thousand times and the odds are better than 998 in 1000 that the percentage of heads will be between 45\% and 55\%.

These results stem from a statistical theorem called the \textbf{law of large numbers}. In English, the law of large numbers says that if you flip a (fair) coin a large number of times, odds are that the proportion of heads will be close to 50\%. (Details \href{http://www.stat.berkeley.edu/~stark/Java/lln.htm}{online}\footnote{http://www.stat.berkeley.edu/\~{}stark/Java/lln.htm} and \href{http://www.ruf.rice.edu/~lane/stat_sim/binom_demo.html}{online}\footnote{http://www.ruf.rice.edu/\~{}lane/stat\_sim/binom\_demo.html}.) %http://www.ruf.rice.edu/~lane/stat_sim/normal_approx/index.html
%http://www.ruf.rice.edu/~lane/stat_sim/binom_demo.html
By extension, if each of a large number of coin flips pays \$10 for heads and \$0 for tails, odds are that you'll come close to averaging \$5 \emph{per coin flip}. It is no coincidence that \$5 also happens to be the expected value of this bet: repeat any bet a large number of times and odds are that the payout \emph{per bet} will be close to the expected value of the bet. This is the sense in which expected value can be thought of as the average payout of a bet.

\subsubsection{Risk and roulette}

To apply the law of large numbers to casinos, note that an individual gambler will play roulette only a few times, but that the casino plays roulette thousands of times each day. The law of large numbers does not apply to the individual gambler, but it does apply to the casino. As a consequence, the individual gambler faces a great deal of risk, \emph{but the casino does not.} Since the expected value from betting \$1 on roulette is $-\$0.05$, odds are extremely good that the casino will gain about \$0.05 for each dollar wagered. As long as the mob doesn't get involved, then, running a casino is not necessarily any riskier than running, say, a photocopy shop. (Go \href{http://www.theonion.com/content/node/38825}{online}\footnote{http://www.theonion.com/content/node/38825} for an amusing story that illustrates this point.)

\subsubsection{Risk and the stock market}

Another application of the law of large numbers is in the stock market, where investors are often advised to \textbf{diversify} their portfolios. Compared to owning one or two stocks, investors can reduce risk by owning many stocks. (One way to do this is to own shares of mutual funds or index funds, companies whose line of business is investing money in the stock market.)

To see how \textbf{diversification} can reduce risk, consider a coin flip that pays \$100 if it comes up heads (H) and \$0 if it comes up tails (T). The risk in this situation is clear: either you win the whole \$100 or you win nothing.

\begin{comment}
The expected value from this coin flip is
\begin{eqnarray*}
EV & = & \Pr(H) \cdot (\$100) + \Pr(T) \cdot (\$0) \\
& = & \frac{1}{2}\cdot (\$100) + \frac{1}{2} \cdot (\$0) \\
& = & \$50.
\end{eqnarray*}
\end{comment}



Now consider flipping two coins, each independently paying \$50 for heads and \$0 for tails. The four possible outcomes---all equally likely---are HH (paying \$100), HT (paying \$50), TH (paying \$50), and TT (paying \$0). Note that the expected value in this situation is \$50:
\begin{eqnarray*}
EV & = & \Pr(HH) \cdot (\$100) + \Pr(HT) \cdot (\$50) + \Pr(TH) \cdot (\$50) + \Pr(TT) \cdot (\$0) \\
& = & \frac{1}{4}\cdot (\$100) + \frac{1}{4}\cdot (\$50) + \frac{1}{4}\cdot (\$50) + \frac{1}{4} \cdot (\$0) = \$50.
\end{eqnarray*}
This is the same expected value as in the one-coin flip situation described above. Compared to the one-coin flip, however, this two-coin flip is less risky: instead of always winning everything or nothing, there is now a 50\% chance of winning something in between. A risk-averse individual should prefer the two-coin flip over the one-coin flip because it has less variability. (In the language of statistics, the two-coin flip has lower \textbf{variance}\index{variance}. In English, the two-coin flip means that you aren't putting all your eggs in one basket.)

The risk inherent in coin-flipping (or stock-picking) can be reduced even further by spreading the risk out even more, i.e., through diversification. Flip twenty coins, each independently paying \$5 for heads and \$0 for tails, and the probability of getting an outcome that is ``in the middle" (say, between \$40 and \$60) is over 70\%. Flip one hundred coins, each independently paying \$1 for heads and \$0 for tails, and the odds of ending up between \$40 and \$60 is over 95\%. And flip one thousand coins, each independently paying \$0.10 for heads and \$0 for tails, and there is a 99.86\% chance that you will end up with an amount between \$45 and \$55. The expected value in all of these situations is \$50; what diversification does is reduce variance, so that with one thousand coin flips you are virtually guaranteed to end up with about \$50.

These coin-flipping results follow directly from the law of large numbers. It is important to note, however, that there is an important difference between coin-flipping and stock-picking: while the outcome of one coin flip has no influence on the outcome of the next coin flip, stocks have a tendency to go up or down together. (In statistical terms, coin flips are \textbf{independent} while the prices of different stocks are \textbf{correlated}.) The law of large numbers applies to risks that are independent, so diversification of a stock market portfolio can reduce or eliminate risks that affect companies independently. But the law of large numbers does not apply when risks are correlated: diversification cannot reduce the risk of stock market booms or busts or other systemic risks that affect the entire economy.

A final point is that diversification is not always painless. It's easy to diversify if you have no preference for one stock over another---and Chapter~\ref{1transition} suggests that this is a reasonable position to take. But if you have favorites then you have to balance risks against rewards: investing your life savings in your favorite stock may give you the highest expected payoff, but it also exposes you to a great deal of risk; diversifying your portfolio reduces risk, but it may also reduce your expected payoff. The optimal behavior in such situations is the subject of \textbf{portfolio selection theory}, a branch of economics whose development helped win James Tobin the Nobel Prize in Economics in 1981. Professor Tobin died in 2002; his  obituary in the \emph{New York Times} (available  \href{http://cowles.econ.yale.edu/archive/people/tobin/nyt_obit.htm}{online}\footnote{http://cowles.econ.yale.edu/archive/people/tobin/nyt\_obit.htm}) included the following story:
\begin{quote}
After he won the Nobel Prize, reporters asked him to explain the portfolio theory. When he tried to do so, one journalist interrupted, ``Oh, no, please explain it in lay language." So he described the theory of diversification by saying: ``You know, don't put your eggs in one basket." Headline writers around the world the next day created some version of ``Economist Wins Nobel for Saying, `Don't Put Eggs in One Basket'."
\end{quote}


% FIX: Do Akerlof's Market for Lemons!

\begin{CALCULUS}

\section{\emph{Math}: Indifference Curves\index{expected value!and indifference curve|(}\index{indifference curve!and expected value|(}}

A more mathematical treatment of this material allows us introduce \textbf{indifference curves\index{indifference}}: we can ask when an individual is indifferent (i.e., has no preference) between one risky situation and another, or between a risky situation and a riskless one. For example, consider a coin-flipping bet in which someone wins \$100 for heads and \$0 for tails. Presumably this person would be indifferent between this bet and a symmetric bet in which he wins \$100 for tails and \$0 for heads. (If we refer to the first bet using the notation $(100,0)$, then the notation $(0,100)$ describes the second bet.) In fact, there are probably an infinite number of pairs $(x, y)$ such that he'd be indifferent between the bet $(100,0)$ and the bet $(x,y)$, i.e., a bet in which he wins $\$x$ for heads and $\$y$ for tails. If we graph all these pairs we get an indifference curve like the one in Figure~\ref{indifference:ev}. Using the utility-maximization idea described in Chapter~\ref{1intro}, we can say that all the points on this indifference curve have the same utility.



\psset{unit=.04cm}
\begin{figure}
\begin{center}
\begin{pspicture}(0,0)(110,110)
\rput[b](-8,108){$w_2$}
\rput[l](108,-5){$w_1$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](0,100){1}
\rput[l](4,100){$(0,100)$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](100,0){1}
\rput[b](105,4){$(100,0)$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](36.6,36.6){1}
\rput[lb](38,38){$(37,37)$}
\psplot{0}{100}{100 .02 mul 1 add .02 x mul 1 add div 1 sub .02 div} % add sub div mul exp log
\psaxes[labels=none, ticks=none, showorigin=false](110,110)
\end{pspicture}
\end{center}
\caption{An indifference curve for a coin-flipping bet}
\label{indifference:ev}
\end{figure}
\psset{unit=.5cm}


Of particular interest on this indifference curve is the point where $x=y$, because at this point the individual is not exposed to any uncertainty: regardless of the outcome of the coin flip, he gets the same amount. This amount is called the \textbf{certainty equivalent\index{certainty equivalent} wealth} corresponding to that indifference curve. For the curve in Figure~\ref{indifference:ev}, the certainty equivalent wealth is \$37, meaning that our individual is indifferent between getting \$37 \emph{with certainty} and facing the uncertain bets---such as $(100,0)$ and $(0,100)$---that are on the same indifference curve.

Note that the expected value of the bet $(100,0)$ is \$50, which is \emph{more} than the individual's certainty equivalent wealth. This implies that he is risk-averse; a risk-neutral person would have a certainty equivalent wealth of \$50 for the same original bet of $(100,0)$. The difference between the certainty equivalent wealth of a risk-averse person (in our example, \$37) and that of a risk-neutral person (\$50) makes it possible for insurance companies to provide a benefit to society and still make a profit. If an insurance company offers to ``buy" the bet $(100,0)$ from our risk-neutral individual for, say, \$40, he will accept the offer because he is indifferent between the bet $(100,0)$ and having \$37 with certainty, and having \$40 with certainty is better than having \$37 with certainty. (In the language of economics, accepting the offer of \$40 will put him on a higher indifference curve, i.e., one corresponding to a higher utility level.) What's in it for the insurance company? Well, they spend only \$40 to buy a bet that has an expected value of \$50; by buying many such bets, the insurance company has an extremely good chance of making a profit.

%One important implication here is that insurance companies only serve risk-averse individuals. You have to pay at least the expected value of your loss. So insurance protects against variability, not against expected loss.


\index{indifference curve!and expected value|)}\index{expected value!and indifference curve|)}

\end{CALCULUS}


\begin{EXAM}
\section*{Problems}

\input{part1/qa1uncertainty}
\end{EXAM}

\index{expected value|)}












\begin{comment}
\begin{CALCULUS}

\section{\emph{Math}: Expected Value and Indifference Curves\index{expected value!and indifference curve|(}\index{indifference curve!and expected value|(}}

A more mathematical treatment of this material allows us to do two additional things, both related to expected utility. First, we can see that there is a relationship between the second derivative of the utility function and the individual's attitude toward risk\index{risk}. This result follows from comparing $E\left( u(w)\right)$ and $u\left( E(w)\right)$ using a theorem called Jensen's Inequality. The end result is this:
\begin{itemize}
\item For a concave utility function ($u''<0$, e.g., $u(w)=\sqrt{w}$) Jensen's Inequality says that $E\left[u(w)\right]<u\left[ E(w)\right]$, so this individual is risk\index{risk} averse.

\item For a convex utility function ($u''>0$, e.g., $u(w)=w^2$) Jensen's Inequality says that $E\left[ u(w)\right]>u\left[E(w)\right]$, so this individual is risk\index{risk} loving.

\item For a linear utility function ($u''=0$, e.g., $u(w)=w$) Jensen's Inequality says that $E\left[ u(w)\right]=u\left[E(w)\right]$, so this individual is risk\index{risk} neutral.
\end{itemize}
%

The second additional topic is \textbf{indifference\index{indifference}}: we can ask when an individual is indifferent (i.e., has no preference) between one risky situation and another, or between a risky situation and a riskless one. For example, consider an individual who has a 40\% chance of having wealth $w_1$ and a 60\% chance of having wealth $w_2$. Her utility function is $u(w)=\sqrt{w}$, and she maximizes expected utility, $E[u(w)]=.4\sqrt{w_1}+.6\sqrt{w_2}$. If $(w_1,w_2)=(0,100)$, her expected utility is $.4\sqrt{0}+.6\sqrt{100}=.6(10)=6$. If $(w_1,w_2)=(225,0)$ her expected utility is $.4\sqrt{225}+.6\sqrt{0}=.4(15)=6$. Since her expected utility is the same in both cases, she is indifferent between them.

In fact, there are an infinite number of pairs $(w_1,w_2)$ that satisfy $E[u(w)]=6$. Figure~\ref{indifference:ev} shows a graph of these points, which is a called an \textbf{indifference curve}. In this case, the indifference curve corresponds to an expected utility of 6: every point $(w_1,w_2)$ on the curve gives our individual an expected utility of 6, and so she is indifferent between any two of them.

\psset{unit=.5cm}
\begin{figure}
\begin{center}
\begin{pspicture}(0,0)(21,10)
\rput[b](0,10.2){$w_2$}
\rput[l](21.2,0){$w_1$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](0,8.888){.1}
\rput[l](.4,8.888){$(0,100)$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](20,0){.1}
\rput[b](20,.4){$(225,0)$}
\pscircle[fillstyle=solid, linecolor=black, fillcolor=black](3.2,3.2){.1}
\rput[lb](3.3,3.3){$(36,36)$}
\psplot{0}{20}{60 11.25 x mul sqrt 4 mul sub 2 exp 36 div 11.25 div} % add sub div mul exp log
\psaxes[labels=none, ticks=none, showorigin=false](21,10)
\end{pspicture}
\end{center}
\caption{An indifference curve corresponding to expected utility of 6}
\label{indifference:ev}
\end{figure}
\psset{unit=.5cm}


In particular, note that the point $(w_1,w_2)=(36,36)$ lies on this indifference curve: $E[u(w)]=.4\sqrt{36}+.6\sqrt{36}=\sqrt{36}=6$. In this situation our individual has a 40\% chance of having wealth $w_1=36$ and a 60\% chance of having wealth $w_2=36$, i.e., a 100\% chance of having wealth $w=36.$ This amount of wealth is therefore called the \textbf{certainty equivalent\index{certainty equivalent}} wealth corresponding to an expected utility of 6.

\subsubsection*{Example: \rm An individual with initial wealth of 400 has a 10\% chance of getting in an accident. If she gets in an accident, she will lose 300; if she doesn't, she loses nothing. She maximizes expected utility, and her utility function is $u(w)=\sqrt{w}$.
\begin{enumerate}
\item What is the expected amount of money she will lose?
%
\item What is her expected utility?
%
\item What is her certainty equivalent wealth?
%
\item What is the maximum amount she would pay for \textbf{full insurance\index{insurance!full}}? (Note: Full insurance totally insulates her from the risk\index{risk} of an accident. If she pays $x$ for full insurance, her wealth will be $400-x$ regardless of whether or not she gets in an accident.)
%
\item How much more is she willing to pay for insurance than would a risk\index{risk}-neutral individual? (This amount is called her \textbf{risk premium}.)
\end{enumerate}}

Answer: Her expected loss is $.1(300)+.9(0)=30.$ Her expected utility is $.1\sqrt{400-300}+.9\sqrt{400-0}=19.$ Her certainty equivalent wealth is $w$ such that having wealth of $w$ with probability $1$ gives her an expected utility of $19$: $\sqrt{w}=19\Longrightarrow w=361.$

The maximum amount she would pay for full insurance is $400-361=39.$ This payment makes her indifferent between buying insurance, in which case $E[u(w)]=.1\sqrt{400-39}+.9\sqrt{400-39}=\sqrt{361}=19$, and not buying insurance, in which case $E[u(w)]=.1\sqrt{400-300}+.9\sqrt{400-0}=19$. To look at it another way: if she is offered insurance for some amount $x<39$, she will take it because $u(400 - x)>19$; if she is offered insurance for some amount $x>39$, she will refuse it because $u(400-x)<19$; if she is offered insurance for $x=39$ she will be indifferent between accepting and rejecting.

Finally, we can calculate her risk premium\index{risk!premium} in this situation. She is willing to pay up to 39 for full insurance, but her expected loss is only 30; since a risk\index{risk} neutral individual would pay a maximum of 30 for full insurance, the difference ($39-30=9$) is her risk premium\index{risk!premium}. Its source is risk\index{risk} aversion: our individual is willing to pay money to avoid a fair bet\index{fair bet}. We can see that she is risk\index{risk} averse by calculating the second derivative of the utility function $u(w)=\sqrt{w}$: $u'(w)=\frac{1}{2}w^{-\frac{1}{2}}$, so $u''(w)=-\frac{1}{4}w^{-\frac{3}{2}}<0.$\index{indifference curve!and expected value|)}\index{expected value!and indifference curve|)}

\end{CALCULUS}
\end{comment} 